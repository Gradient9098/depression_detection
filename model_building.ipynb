{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4OIpSCWsm2o"
      },
      "source": [
        "# Goal Is to reduce the parameters needed to detect depression so that it could be used on edge devices (Apples autocorrect can detect and help users find mental health sources) rather than needing expensive API requests to a remote LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDN7zCaPB9bX",
        "outputId": "50660149-3510-4843-8652-1ce1bd269c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "directory = './depression-detection-lt-edi-2022/data/original_dataset/'\n",
        "if not os.path.exists(directory):\n",
        "    !git clone https://github.com/rafalposwiata/depression-detection-lt-edi-2022.git\n",
        "    print(\"Dataset has been cloned.\")\n",
        "else:\n",
        "    print(\"Dataset already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr457E5UCmPM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# # Getting the data files\n",
        "# files = []\n",
        "# for filename in os.listdir(directory):\n",
        "#     f = os.path.join(directory, filename)\n",
        "\n",
        "#     if os.path.isfile(f):\n",
        "#         print(f.split('.')[1][1:])\n",
        "#         files.append(f.split('.')[1][1:])\n",
        "# print(os.listdir(directory))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuvCs7ZnlR7y"
      },
      "outputs": [],
      "source": [
        "# Storing the data in a panda table\n",
        "df_train = pd.read_table(directory + \"train.tsv\")\n",
        "df_dev = pd.read_table(directory + \"dev.tsv\")\n",
        "df_test = pd.read_table(directory + \"test.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvSRCLMOlR7z"
      },
      "outputs": [],
      "source": [
        "# Making the column names consistent\n",
        "df_train.rename(columns={\"PID\":\"pid\", \"Text_data\":\"text_data\", \"Label\":\"label\"}, inplace=True)\n",
        "df_dev.rename(columns={\"PID\":\"pid\", \"Text data\":\"text_data\", \"Label\":\"label\"}, inplace=True)\n",
        "df_test.rename(columns={\"Pid\":\"pid\", \"text data\":\"text_data\", \"Class labels\":\"label\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgU3yfhiPTj0"
      },
      "outputs": [],
      "source": [
        "# Converting from strings to ints for the labels\n",
        "label_mapping = {\n",
        "    'moderate': 0,\n",
        "    'not depression': 1,\n",
        "    'severe': 2\n",
        "}\n",
        "df_train['label'] = df_train['label'].map(label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y61k3rKnx79N",
        "outputId": "8f95b00a-2db2-43c6-e06e-c7e8ba5800df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the longest 'text_data' string is: 15996\n"
          ]
        }
      ],
      "source": [
        "max_length = 0\n",
        "for text in df_train['text_data']:\n",
        "  max_length = max(max_length, len(text))\n",
        "\n",
        "print(f\"The length of the longest 'text_data' string is: {max_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9TezfGyp3VW"
      },
      "outputs": [],
      "source": [
        "my_data = []\n",
        "for data in df_train['text_data']:\n",
        "  my_data.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IZkBF5kElDl",
        "outputId": "4551e870-19d0-45ca-9d58-2cc07dbd6a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "# For linux\n",
        "#!export CUDA_LAUNCH_BLOCKING=1\n",
        "# For windows\n",
        "#!set CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "import os\n",
        "# Set CUDA_LAUNCH_BLOCKING to 1\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class DepressionDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=1024):\n",
        "        self.texts = dataframe['text_data'].tolist()\n",
        "        self.labels = dataframe['label'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "dataset = DepressionDataset(df_train, tokenizer)\n",
        "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# for batch in data_loader:\n",
        "#     print(\"Input IDs:\", batch['input_ids'].to(device), \"Input IDs type:\", type(batch['input_ids']))\n",
        "#     print(\"Attention Mask:\", batch['attention_mask'].to(device))\n",
        "#     print(\"Labels:\", batch['label'].to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyj1z8CPvV_Y"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = \"cpu\"\n",
        "vocab_size = tokenizer.vocab_size\n",
        "for batch in data_loader:\n",
        "    input_ids = batch['input_ids'].type(torch.long).to(device)\n",
        "\n",
        "    # Check for out-of-vocabulary tokens before moving to GPU\n",
        "    out_of_vocab_mask = input_ids >= tokenizer.vocab_size\n",
        "    if out_of_vocab_mask.any():\n",
        "        print(\"Found input IDs out of vocabulary bounds!\")\n",
        "        # Print the offending tokens (if needed)\n",
        "        print(\"Offending tokens:\", tokenizer.convert_ids_to_tokens(input_ids[out_of_vocab_mask].tolist()))\n",
        "        # Replace out-of-vocabulary tokens with a special token (e.g., [UNK])\n",
        "        input_ids[out_of_vocab_mask] = tokenizer.unk_token_id  # Replace with tokenizer.unk_token_id\n",
        "\n",
        "    input_ids = batch['input_ids'].type(torch.long).to(device)\n",
        "    if (input_ids >= vocab_size).any():\n",
        "        print(\"Found input IDs out of vocabulary bounds!\")\n",
        "        print(input_ids[input_ids >= vocab_size])\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZrnUSTWQH3H"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class MHA(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads=8, dropout=0.4):\n",
        "        super(MHA, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.fc_q = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc_k = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc_v = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc_o = nn.Linear(embed_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.classifier = nn.Linear(embed_dim, 3)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.embedding(input_ids)\n",
        "        batch_size = x.size(0)\n",
        "        q = self.fc_q(x)\n",
        "        k = self.fc_k(x)\n",
        "        v = self.fc_v(x)\n",
        "        q = q.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        k = k.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        v = v.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        attn_weights = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "        attn_weights = torch.softmax(attn_weights, dim=-1)\n",
        "        attn_output = torch.matmul(attn_weights, v)\n",
        "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.embed_dim)\n",
        "        output = self.fc_o(attn_output)\n",
        "        output = self.relu(output)\n",
        "        output = self.dropout(output)\n",
        "        output = self.layer_norm(output + x)\n",
        "        output = self.classifier(output)\n",
        "        output = output[:, 0, :]\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "mha_model = MHA(vocab_size=tokenizer.vocab_size, embed_dim=768).to(device)\n",
        "\n",
        "optimizer = optim.Adam(mha_model.parameters(), lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loop = tqdm(data_loader, leave=True, desc=f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(loop):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].type(torch.long).to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = mha_model(input_ids)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        loop.set_postfix(loss=running_loss / (i + 1))"
      ],
      "metadata": {
        "id": "hV8JXoP8nl8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d405eb-c117-4dd7-807b-eacb87db5a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/10]: 100%|██████████| 2223/2223 [02:41<00:00, 13.80it/s, loss=0.796]\n",
            "Epoch [2/10]: 100%|██████████| 2223/2223 [02:21<00:00, 15.76it/s, loss=0.767]\n",
            "Epoch [3/10]: 100%|██████████| 2223/2223 [02:20<00:00, 15.80it/s, loss=0.758]\n",
            "Epoch [4/10]: 100%|██████████| 2223/2223 [02:21<00:00, 15.76it/s, loss=0.742]\n",
            "Epoch [5/10]: 100%|██████████| 2223/2223 [02:22<00:00, 15.64it/s, loss=0.695]\n",
            "Epoch [6/10]: 100%|██████████| 2223/2223 [02:21<00:00, 15.76it/s, loss=0.648]\n",
            "Epoch [7/10]: 100%|██████████| 2223/2223 [02:21<00:00, 15.74it/s, loss=0.605]\n",
            "Epoch [8/10]: 100%|██████████| 2223/2223 [02:20<00:00, 15.77it/s, loss=0.568]\n",
            "Epoch [9/10]: 100%|██████████| 2223/2223 [02:20<00:00, 15.77it/s, loss=0.536]\n",
            "Epoch [10/10]: 100%|██████████| 2223/2223 [02:21<00:00, 15.68it/s, loss=0.506]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzeYmCrfvbzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ad2ccb-e55b-4502-84b4-79932368addf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters: 25807107\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(mha_model)\n",
        "print(f\"Total number of trainable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIME - Making the model explainable.\n",
        "\n",
        "Currently a work in progress. --Zach"
      ],
      "metadata": {
        "id": "c8KD1plmu2Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9fUlLfVo4i9",
        "outputId": "2dbe8c5e-e67d-4975-ee6c-dd9f891b4021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.5.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.24.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDIUg4jMlR79"
      },
      "outputs": [],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "class_names = df_train['label'].unique()\n",
        "explainer = LimeTextExplainer(class_names=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_set = DepressionDataset(df_dev, tokenizer)\n",
        "dev_loader = DataLoader(dev_set, batch_size=1, shuffle=False)\n",
        "\n",
        "dev_data = []\n",
        "for some_data in dev_loader:\n",
        "  dev_data.append(some_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "-dZCBkYLsDr_",
        "outputId": "6d7aa0fa-92c3-4c5b-874f-a3276a51c9d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "new(): invalid data type 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-33ae27f1e881>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msome_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdev_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-0b1682f275c8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         }\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "WrsBY8DqlR7-",
        "outputId": "ca8fdd72-66cd-4dc7-924f-b841cb66e993"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'DataLoader' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d37b2d54b476>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpos_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdatapoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_to_predict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmha_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m exp = explainer.explain_instance(datapoint['text_data'], \n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "pos_to_predict = 0\n",
        "datapoint = df_dev.iloc[pos_to_predict]\n",
        "predicted_class = mha_model.forward(dev_loader[0])\n",
        "\n",
        "exp = explainer.explain_instance(datapoint['text_data'],\n",
        "                                 predicted_class, num_features=6,\n",
        "                                 labels=[0, 1, 2])\n",
        "\n",
        "print(\"Position of element in dataset:\", pos_to_predict)\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "print(\"Actual class:\", datapoint['label'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Explanation for class %s\" % class_names[0])\n",
        "print(\"\\n\".join(map(str, exp.as_list(label=0))))\n",
        "\n",
        "print(\"Explanation for class %s\" % class_names[0])\n",
        "print(\"\\n\".join(map(str, exp.as_list(label=0))))"
      ],
      "metadata": {
        "id": "6JpzBVWipipE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}